{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from english_words import english_words_set\n",
    "\n",
    "from skimage import io, color, filters\n",
    "from skimage.transform import resize, rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25487"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words_list = list(english_words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlst = english_words_list[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 0\n",
    "# while x <= 10:\n",
    "#     for word in english_words_set:\n",
    "#         print(word)\n",
    "#         print(x)\n",
    "#         x = x + 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Now is the time for all good men to come to the aid of their country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image(word):\n",
    "    y = word \n",
    "    plt.text(1,1, y, size = 'xx-large')\n",
    "    plt.xlim([0,2])\n",
    "    plt.ylim([0,2])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'Img/{y}.jpg')\n",
    "    plt.close()\n",
    "    X = np.array(Image.open(f'Img/{y}.jpg'))\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 2.0, 0.0, 2.0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = word \n",
    "plt.text(1,1, y, size = 'x-large')\n",
    "plt.xlim([0,2])\n",
    "plt.ylim([0,2])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = [] \n",
    "indices = [] \n",
    "for idx, wrd in enumerate(shortlst): \n",
    "    img, lab = make_image(wrd)\n",
    "    images.append(img)\n",
    "    labels.append(lab)\n",
    "    indices.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Images</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semiramis</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exist</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eugenia</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>illustrious</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bothersome</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Labels                                             Images  Class\n",
       "0    Semiramis  [[[255, 255, 255], [255, 255, 255], [255, 255,...      0\n",
       "1        exist  [[[255, 255, 255], [255, 255, 255], [255, 255,...      1\n",
       "2      Eugenia  [[[255, 255, 255], [255, 255, 255], [255, 255,...      2\n",
       "3  illustrious  [[[255, 255, 255], [255, 255, 255], [255, 255,...      3\n",
       "4   bothersome  [[[255, 255, 255], [255, 255, 255], [255, 255,...      4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"Labels\"] = labels\n",
    "df[\"Images\"] = images\n",
    "df[\"Class\"] = indices\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "new_labels = lb.fit_transform(indices)\n",
    "lb.classes_\n",
    "new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X = np.array(images)\n",
    "y = np.array(new_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 288, 432, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape, nb_classes, dropout, nb_filters, kernel_size,  pool_size, activation='tanh',optimizer='adadelta'):    \n",
    "    model = Sequential()  # model is a linear stack of layers (don't change)\n",
    "\n",
    "    # note: the convolutional layers and dense layers require an activation function\n",
    "    # see https://keras.io/activations/\n",
    "    # and https://en.wikipedia.org/wiki/Activation_function\n",
    "    # options: 'linear', 'sigmoid', 'tanh', 'relu', 'softplus', 'softsign'\n",
    "\n",
    "    model.add(Conv2D(nb_filters,\n",
    "                     (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid',\n",
    "                     input_shape=input_shape))  # first conv. layer  KEEP\n",
    "    model.add(Activation(activation))  # Activation specification necessary for Conv2D and Dense layers\n",
    "\n",
    "    model.add(Conv2D(nb_filters,\n",
    "                     (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid'))  # 2nd conv. layer KEEP\n",
    "    model.add(Activation(activation))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))  # decreases size, helps prevent overfitting\n",
    "    model.add(Dropout(dropout))  # zeros out some fraction of inputs, helps prevent overfitting\n",
    "\n",
    "    model.add(Flatten())  # necessary to flatten before going into conventional dense layer  KEEP\n",
    "    print('Model flattened out to ', model.output_shape)\n",
    "\n",
    "    # now start a typical neural network\n",
    "    model.add(Dense(32))  # (only) 32 neurons in this layer, really?   KEEP\n",
    "    model.add(Activation(activation))\n",
    "\n",
    "    model.add(Dropout(dropout))  # zeros out some fraction of inputs, helps prevent overfitting\n",
    "\n",
    "    model.add(Dense(nb_classes))  # 10 final nodes (one for each class)  KEEP\n",
    "    model.add(Activation('softmax'))  # softmax at end to pick between classes 0-9 KEEP\n",
    "\n",
    "    # many optimizers available, see https://keras.io/optimizers/#usage-of-optimizers\n",
    "    # suggest you KEEP loss at 'categorical_crossentropy' for this multiclass problem,\n",
    "    # and KEEP metrics at 'accuracy'\n",
    "    # suggest limiting optimizers to one of these: 'adam', 'adadelta', 'sgd'\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer)\n",
    "                  #metrics=['accuracy'], learning)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 100)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 285, 429, 12)      588       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 285, 429, 12)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 282, 426, 12)      2316      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 282, 426, 12)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 141, 213, 12)      0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 141, 213, 12)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 360396)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                11532704  \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 11,538,908\n",
      "Trainable params: 11,538,908\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model flattened out to  (None, 360396)\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 10s 10s/step - loss: 4.6986 - val_loss: 4.6126\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.6478 - val_loss: 4.6462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# important inputs to the model: don't changes the ones marked KEEP in the functions above\n",
    "batch_size = 5000  # number of training samples used at a time to update the weights\n",
    "nb_epoch = 2       # number of passes through the entire train dataset before weights \"final\"\n",
    "nb_filters = 12    # number of convolutional filters to use\n",
    "pool_size = (2, 2)  # pooling decreases image size, reduces computation, adds translational invariance\n",
    "kernel_size = (4, 4)  # convolutional kernel size, slides over image to learn features\n",
    "dropout = 0.1\n",
    "activation='tanh'\n",
    "optimizer='adadelta'\n",
    "img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "input_shape = (img_rows,img_cols,3)\n",
    "nb_classes = len(indices)\n",
    "\n",
    "model = define_model(input_shape, nb_classes, dropout, nb_filters, kernel_size, pool_size)\n",
    "\n",
    "# during fit process watch train and test error simultaneously\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 4.64615535736084\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-3a7286003a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is the one we care about\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print('Test score:', score)\n",
    "print('Test accuracy:', score[1])  # this is the one we care about"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
