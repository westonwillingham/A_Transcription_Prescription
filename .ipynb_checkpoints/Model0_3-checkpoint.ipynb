{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weston/anaconda3/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from english_words import english_words_set\n",
    "\n",
    "from skimage import io, color, filters\n",
    "from skimage.transform import resize, rotate\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlst = [\"lions\", 'tigers', \"bears\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image():\n",
    "    word = np.random.choice(shortlst)\n",
    "    size = np.random.uniform(45,50)\n",
    "    xpos = np.random.uniform(0,1.2)\n",
    "    ypos = np.random.uniform(0,1.2)\n",
    "    y = word\n",
    "    #print(y)\n",
    "    plt.text(1,1, y, size = size)\n",
    "    plt.xlim([0,2])\n",
    "    plt.ylim([0,2])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'data/{y}.jpg')\n",
    "    plt.close()\n",
    "    X = np.array(Image.open(f'data/{y}.jpg'))\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = [] \n",
    "for wrd in range(1000): \n",
    "    img, lab = make_image()\n",
    "    images.append(img)\n",
    "    labels.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "new_labels = lb.fit_transform(labels)\n",
    "lb.classes_\n",
    "new_labels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X = np.array(images)\n",
    "y = np.array(new_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape, nb_classes, dropout, nb_filters, kernel_size,  pool_size, activation='relu',optimizer='adam'):    \n",
    "    model = Sequential()  # model is a linear stack of layers (don't change)\n",
    "\n",
    "    # note: the convolutional layers and dense layers require an activation function\n",
    "    # see https://keras.io/activations/\n",
    "    # and https://en.wikipedia.org/wiki/Activation_function\n",
    "    # options: 'linear', 'sigmoid', 'tanh', 'relu', 'softplus', 'softsign'\n",
    "\n",
    "    model.add(Conv2D(nb_filters,\n",
    "                     (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid',\n",
    "                     input_shape=input_shape))  # first conv. layer  KEEP\n",
    "    model.add(Activation(activation))  # Activation specification necessary for Conv2D and Dense layers\n",
    "\n",
    "    model.add(Conv2D(nb_filters,\n",
    "                     (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid'))  # 2nd conv. layer KEEP\n",
    "    model.add(Activation(activation))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))  # decreases size, helps prevent overfitting\n",
    "    model.add(Dropout(dropout))  # zeros out some fraction of inputs, helps prevent overfitting\n",
    "\n",
    "    model.add(Flatten())  # necessary to flatten before going into conventional dense layer  KEEP\n",
    "    print('Model flattened out to ', model.output_shape)\n",
    "\n",
    "    # now start a typical neural network\n",
    "    model.add(Dense(32))  # (only) 32 neurons in this layer, really?   KEEP\n",
    "    model.add(Activation(activation))\n",
    "\n",
    "    model.add(Dropout(dropout))  # zeros out some fraction of inputs, helps prevent overfitting\n",
    "\n",
    "    model.add(Dense(nb_classes))  # 10 final nodes (one for each class)  KEEP\n",
    "    model.add(Activation('softmax'))  # softmax at end to pick between classes 0-9 KEEP\n",
    "\n",
    "    # many optimizers available, see https://keras.io/optimizers/#usage-of-optimizers\n",
    "    # suggest you KEEP loss at 'categorical_crossentropy' for this multiclass problem,\n",
    "    # and KEEP metrics at 'accuracy'\n",
    "    # suggest limiting optimizers to one of these: 'adam', 'adadelta', 'sgd'\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 285, 429, 6)       294       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 285, 429, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 282, 426, 6)       582       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 282, 426, 6)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 70, 106, 6)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 70, 106, 6)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 44520)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1424672   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,425,647\n",
      "Trainable params: 1,425,647\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model flattened out to  (None, 180198)\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 35s 703ms/step - loss: 693.3551 - accuracy: 0.6185 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 35s 696ms/step - loss: 0.0541 - accuracy: 0.9942 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 0.0511 - accuracy: 0.9901 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "14/50 [=======>......................] - ETA: 35s - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "\n",
    "# important inputs to the model: don't changes the ones marked KEEP in the functions above\n",
    "batch_size = 16 # number of training samples used at a time to update the weights\n",
    "nb_epoch = 10      # number of passes through the entire train dataset before weights \"final\"\n",
    "nb_filters = 6    # number of convolutional filters to use\n",
    "pool_size = (2,2)  # pooling decreases image size, reduces computation, adds translational invariance\n",
    "kernel_size = (4, 4)  # convolutional kernel size, slides over image to learn features\n",
    "dropout = 0.1\n",
    "activation='relu'\n",
    "optimizer='adam'\n",
    "img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "input_shape = (img_rows,img_cols,3)\n",
    "nb_classes = len(shortlst)\n",
    "\n",
    "model = define_model(input_shape, nb_classes, dropout, nb_filters, kernel_size, pool_size)\n",
    "\n",
    "# during fit process watch train and test error simultaneously\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9175918102264404, 0.36500000953674316]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
