{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from english_words import english_words_set\n",
    "\n",
    "from skimage import io, color, filters\n",
    "from skimage.transform import resize, rotate\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlst = [\"lions\", 'tigers', \"bears\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image():\n",
    "    word = np.random.choice(shortlst)\n",
    "    size = np.random.uniform(20,70)\n",
    "    xpos = np.random.uniform(0,1.2)\n",
    "    ypos = np.random.uniform(0,1.2)\n",
    "    rot = np.random.uniform(-30,30)\n",
    "    y = word\n",
    "    #print(y)\n",
    "    plt.text(xpos,ypos, y, size = size, rotation = rot)\n",
    "    plt.xlim([0,2])\n",
    "    plt.ylim([0,2])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'data/{y}.jpg')\n",
    "    plt.close()\n",
    "    X = np.array(Image.open(f'data/{y}.jpg'))\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = [] \n",
    "for wrd in range(5000): \n",
    "    img, lab = make_image()\n",
    "    images.append(img)\n",
    "    labels.append(lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "new_labels = lb.fit_transform(labels)\n",
    "lb.classes_\n",
    "new_labels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X = np.array(images)\n",
    "y = np.array(new_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape, nb_classes, dropout, nb_filters, kernel_size,  pool_size, activation='relu',optimizer='adam'):    \n",
    "    model = Sequential()  # model is a linear stack of layers (don't change)\n",
    "\n",
    "    # note: the convolutional layers and dense layers require an activation function\n",
    "    # see https://keras.io/activations/\n",
    "    # and https://en.wikipedia.org/wiki/Activation_function\n",
    "    # options: 'linear', 'sigmoid', 'tanh', 'relu', 'softplus', 'softsign'\n",
    "\n",
    "    model.add(Conv2D(nb_filters,\n",
    "                     (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid',\n",
    "                     input_shape=input_shape))  # first conv. layer  KEEP\n",
    "    model.add(Activation(activation))  # Activation specification necessary for Conv2D and Dense layers\n",
    "\n",
    "    model.add(Conv2D(nb_filters,\n",
    "                     (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid'))  # 2nd conv. layer KEEP\n",
    "    model.add(Activation(activation))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))  # decreases size, helps prevent overfitting\n",
    "    model.add(Dropout(dropout))  # zeros out some fraction of inputs, helps prevent overfitting\n",
    "\n",
    "    model.add(Flatten())  # necessary to flatten before going into conventional dense layer  KEEP\n",
    "    print('Model flattened out to ', model.output_shape)\n",
    "\n",
    "    # now start a typical neural network\n",
    "    model.add(Dense(32))  # (only) 32 neurons in this layer, really?   KEEP\n",
    "    model.add(Activation(activation))\n",
    "\n",
    "    model.add(Dropout(dropout))  # zeros out some fraction of inputs, helps prevent overfitting\n",
    "\n",
    "    model.add(Dense(nb_classes))  # 10 final nodes (one for each class)  KEEP\n",
    "    model.add(Activation('softmax'))  # softmax at end to pick between classes 0-9 KEEP\n",
    "\n",
    "    # many optimizers available, see https://keras.io/optimizers/#usage-of-optimizers\n",
    "    # suggest you KEEP loss at 'categorical_crossentropy' for this multiclass problem,\n",
    "    # and KEEP metrics at 'accuracy'\n",
    "    # suggest limiting optimizers to one of these: 'adam', 'adadelta', 'sgd'\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model flattened out to  (None, 300330)\n",
      "Epoch 1/50\n",
      "21/25 [========================>.....] - ETA: 7s - loss: 3505.3773 - accuracy: 0.3744"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7f98e96a0fc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# during fit process watch train and test error simultaneously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m history = model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n\u001b[0;32m---> 19\u001b[0;31m           verbose=1, validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# important inputs to the model: don't changes the ones marked KEEP in the functions above\n",
    "batch_size = 32 # number of training samples used at a time to update the weights\n",
    "nb_epoch = 50      # number of passes through the entire train dataset before weights \"final\"\n",
    "nb_filters = 10    # number of convolutional filters to use\n",
    "pool_size = (2,2)  # pooling decreases image size, reduces computation, adds translational invariance\n",
    "kernel_size = (4, 4)  # convolutional kernel size, slides over image to learn features\n",
    "dropout = 0.1\n",
    "activation='relu'\n",
    "optimizer='adam'\n",
    "img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "input_shape = (img_rows,img_cols,3)\n",
    "nb_classes = len(shortlst)\n",
    "\n",
    "model = define_model(input_shape, nb_classes, dropout, nb_filters, kernel_size, pool_size)\n",
    "\n",
    "# during fit process watch train and test error simultaneously\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 246s 2s/step - loss: 1.3541 - accuracy: 0.3798 - val_loss: 1.0728 - val_accuracy: 0.4520\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 266s 2s/step - loss: 0.8087 - accuracy: 0.6440 - val_loss: 1.0451 - val_accuracy: 0.4930\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 251s 2s/step - loss: 0.3577 - accuracy: 0.8972 - val_loss: 1.1318 - val_accuracy: 0.5400\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 253s 2s/step - loss: 0.1481 - accuracy: 0.9643 - val_loss: 1.6192 - val_accuracy: 0.5010\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 255s 2s/step - loss: 0.0594 - accuracy: 0.9868 - val_loss: 1.9972 - val_accuracy: 0.4820\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0555 - accuracy: 0.9862 - val_loss: 2.0551 - val_accuracy: 0.4860\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0396 - accuracy: 0.9890 - val_loss: 2.1415 - val_accuracy: 0.4820\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 254s 2s/step - loss: 0.0194 - accuracy: 0.9955 - val_loss: 2.6392 - val_accuracy: 0.4660\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 254s 2s/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 2.4676 - val_accuracy: 0.4690\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 254s 2s/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 3.0191 - val_accuracy: 0.4490\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 254s 2s/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 3.6614 - val_accuracy: 0.4130\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 254s 2s/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 2.3312 - val_accuracy: 0.4570\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 254s 2s/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 3.1969 - val_accuracy: 0.4550\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 255s 2s/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 2.3496 - val_accuracy: 0.4430\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0088 - accuracy: 0.9962 - val_loss: 2.7477 - val_accuracy: 0.4670\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 255s 2s/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 3.9257 - val_accuracy: 0.4270\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 256s 2s/step - loss: 0.0488 - accuracy: 0.9862 - val_loss: 3.6183 - val_accuracy: 0.4300\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 256s 2s/step - loss: 0.0302 - accuracy: 0.9918 - val_loss: 3.3151 - val_accuracy: 0.4420\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 256s 2s/step - loss: 0.0190 - accuracy: 0.9960 - val_loss: 3.1163 - val_accuracy: 0.4630\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 255s 2s/step - loss: 0.0220 - accuracy: 0.9945 - val_loss: 4.3351 - val_accuracy: 0.4440\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 256s 2s/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 6.4623 - val_accuracy: 0.4300\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0166 - accuracy: 0.9960 - val_loss: 4.7276 - val_accuracy: 0.4540\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 256s 2s/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 4.5825 - val_accuracy: 0.4410\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 4.8656 - val_accuracy: 0.4460\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 5.2694 - val_accuracy: 0.4440\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 4.6232 - val_accuracy: 0.4410\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 4.7470 - val_accuracy: 0.4610\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 4.6087 - val_accuracy: 0.4330\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0209 - accuracy: 0.9960 - val_loss: 3.6324 - val_accuracy: 0.4640\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0411 - accuracy: 0.9883 - val_loss: 3.2898 - val_accuracy: 0.4670\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0319 - accuracy: 0.9942 - val_loss: 3.6262 - val_accuracy: 0.4510\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0143 - accuracy: 0.9948 - val_loss: 5.2758 - val_accuracy: 0.4180\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0194 - accuracy: 0.9960 - val_loss: 7.4182 - val_accuracy: 0.4140\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0435 - accuracy: 0.9950 - val_loss: 4.1427 - val_accuracy: 0.4170\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 4.5426 - val_accuracy: 0.4310\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 4.1291 - val_accuracy: 0.4320\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 5.0801 - val_accuracy: 0.4330\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 4.8562 - val_accuracy: 0.4460\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 4.9926 - val_accuracy: 0.4440\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 4.8336 - val_accuracy: 0.4220\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 5.1513 - val_accuracy: 0.4340\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 4.6833 - val_accuracy: 0.4410\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 5.0852 - val_accuracy: 0.4440\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0155 - accuracy: 0.9983 - val_loss: 4.3991 - val_accuracy: 0.4390\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 6.5035 - val_accuracy: 0.4200\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 5.3623 - val_accuracy: 0.4390\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 6.1428 - val_accuracy: 0.4300\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 257s 2s/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 5.5671 - val_accuracy: 0.4360\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 4.4989 - val_accuracy: 0.4720\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 258s 2s/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 4.8643 - val_accuracy: 0.4520\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scorelst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b3c4bc2ad2ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mscorelst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scorelst' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    images = []\n",
    "    labels = [] \n",
    "    for wrd in range(5000): \n",
    "        img, lab = make_image()\n",
    "        images.append(img)\n",
    "        labels.append(lab)\n",
    "    lb = LabelBinarizer()\n",
    "    new_labels = lb.fit_transform(labels)\n",
    "    X = np.array(images)\n",
    "    y = np.array(new_labels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    scorelst.append(score)\n",
    "    print(score)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#score = model.evaluate(X_test, y_test, verbose=0)\n",
    "scorelst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,  verbose=1, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(X_test, y_test, verbose=0)\n",
    "# score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
